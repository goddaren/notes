{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建Tensor\n",
    "\n",
    "\"tensor\"这个单词一般可译作“张量”，张量可以看作是一个多维数组。标量可以看作是0维张量，向量可以看作1维张量，矩阵可以看作是二维张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化一个张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.0516, 0.9107, 0.1519],\n",
      "        [0.2697, 0.0395, 0.9326],\n",
      "        [0.0055, 0.9031, 0.2970],\n",
      "        [0.4191, 0.0706, 0.0036],\n",
      "        [0.2803, 0.5047, 0.1042]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([5.5000, 3.0000])\n",
      "torch.float32\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#创建一个5x3的未初始化的Tensor\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "#创建一个5x3的随机初始化的Tensor\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "#创建一个5x3的long型全0的Tensor\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "#直接根据数据创建\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)\n",
    "print(x.dtype) #默认是float32\n",
    "#还可以通过现有的Tensor来创建，此方法会默认重用输入Tensor的一些属性，例如数据类型，除非自定义数据类型。\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor运算，要注意如下几点：\n",
    "- y = x + y，y的对象地址会被改变，也就是说，Tensor运算后，会生成一个新的Tensor对象，而不是在原有的Tensor对象上进行运算。\n",
    "- y += x，y的对象地址不会改变，而是在原有的Tensor对象上进行运算。\n",
    "- 可以用函数实现对应基本运算，注意PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_(), y.add_(x)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3820,  2.5705,  3.3092],\n",
      "        [ 4.7309,  5.0341,  6.6097],\n",
      "        [ 7.6664,  8.5918,  9.5258],\n",
      "        [10.3557, 11.6479, 12.8001],\n",
      "        [13.1058, 14.5395, 15.5730]])\n",
      "tensor([[ 1.3820,  2.5705,  3.3092],\n",
      "        [ 4.7309,  5.0341,  6.6097],\n",
      "        [ 7.6664,  8.5918,  9.5258],\n",
      "        [10.3557, 11.6479, 12.8001],\n",
      "        [13.1058, 14.5395, 15.5730]])\n",
      "tensor([[ 1.3820,  2.5705,  3.3092],\n",
      "        [ 4.7309,  5.0341,  6.6097],\n",
      "        [ 7.6664,  8.5918,  9.5258],\n",
      "        [10.3557, 11.6479, 12.8001],\n",
      "        [13.1058, 14.5395, 15.5730]])\n",
      "tensor([[ 1.3820,  2.5705,  3.3092],\n",
      "        [ 4.7309,  5.0341,  6.6097],\n",
      "        [ 7.6664,  8.5918,  9.5258],\n",
      "        [10.3557, 11.6479, 12.8001],\n",
      "        [13.1058, 14.5395, 15.5730]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(range(1,16), dtype=torch.int64).reshape(5,3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x+y)\n",
    "print(torch.add(x, y))\n",
    "#加法：方式2\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "#加法：原地\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引\n",
    "\n",
    "- tensor直接变量赋值（=）是引用。\n",
    "- 用[]索引出来的结果与原数据共享内存。\n",
    "- 深拷贝：clone()，不共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "m1=torch.tensor([[1,2],[3,4]])\n",
    "m2=m1\n",
    "m3=m2[0,:]\n",
    "m3+=1\n",
    "print(m1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变形状\n",
    "\n",
    "- view()，改变形状，共享内存。\n",
    "- reshape()，改变形状，不共享内存（此函数并不能保证返回的是其拷贝，所以不推荐使用）。\n",
    "- item()，将一个标量Tensor转换成一个Python number。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14]])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "广播（复制）机制\n",
    "\n",
    "两个张量的形状不同时，PyTorch会自动触发广播机制：\n",
    "- 先适当复制元素使这两个张量形状相同。然后按元素运算。\n",
    "- 两个张量形状在某个维度上不匹配，但是如果有一个张量这个维度的长度为1，则可以利用广播机制进行计算。否则报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 3],\n",
      "         [4, 5]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3,4]).view(1, 2, 2)\n",
    "y = torch.tensor([1,1,1,1]).view(2, 2, 1)\n",
    "print(x+y) #2x2x2，x的第一个维度复制了一次，y的第三个维度复制了一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m])\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mview(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m+\u001b[39;49my) \u001b[39m#报错，第二个维度不一样且都不为1\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3,4]).view(1, 4, 1)\n",
    "y = torch.tensor([1,1,1,1]).view(2, 2, 1)\n",
    "print(x+y) #报错，第二个维度不一样且都不为1\n",
    "torch.norm(x, 2, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor转NumPy\n",
    "- 使用numpy()\n",
    "\n",
    "NumPy转Tensor\n",
    "- 使用torch.from_numpy()，注意：该函数产生的的Tensor与NumPy数组共享内存，当修改其中一个时，另一个也会被修改。\n",
    "- 使用torch.tensor()，注意：该函数总是会进行数据拷贝，返回的Tensor和原来的数据不再共享内存。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor on GPU\n",
    "- 使用.to(device)将Tensor移动到GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
